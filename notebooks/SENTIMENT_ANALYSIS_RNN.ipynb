{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bb07fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: nvidia-ml-py3==7.352.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (7.352.0)\n",
      "Requirement already satisfied: pydantic==1.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (1.7.4)\n",
      "Requirement already satisfied: nltk==3.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (3.6.2)\n",
      "Requirement already satisfied: pandas==1.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (1.1.5)\n",
      "Requirement already satisfied: scikit-learn==0.24.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (0.24.1)\n",
      "Requirement already satisfied: numpy==1.19.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (1.19.5)\n",
      "Requirement already satisfied: trax==1.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (1.3.7)\n",
      "Requirement already satisfied: transformers==4.5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (4.5.1)\n",
      "Requirement already satisfied: datasets==2.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: gsutil==5.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (5.5)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (4.63.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (2022.9.13)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas==1.1.5->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas==1.1.5->-r ../requirements.txt (line 4)) (2022.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ../requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ../requirements.txt (line 5)) (1.8.1)\n",
      "Requirement already satisfied: gin-config in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: jax in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.3.15)\n",
      "Requirement already satisfied: jaxlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.3.15)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (5.9.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-text in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (2.7.3)\n",
      "Requirement already satisfied: gym in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.26.2)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (4.8.2)\n",
      "Requirement already satisfied: funcsigs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (1.0.2)\n",
      "Requirement already satisfied: t5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.9.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (0.0.53)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (2.28.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (2022.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.11.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.18.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (10.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: gcs-oauth2-boto-plugin>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (3.0)\n",
      "Requirement already satisfied: monotonic>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (1.6)\n",
      "Requirement already satisfied: fasteners>=0.14.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (0.18)\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (22.1.0)\n",
      "Requirement already satisfied: retry-decorator>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (1.1.1)\n",
      "Requirement already satisfied: google-reauth>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (0.1.1)\n",
      "Requirement already satisfied: argcomplete>=1.9.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (2.0.0)\n",
      "Requirement already satisfied: httplib2>=0.18 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (0.21.0)\n",
      "Requirement already satisfied: crcmod>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (1.7)\n",
      "Requirement already satisfied: google-apitools>=0.5.32 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (0.5.32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: boto>=2.29.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (2.49.0)\n",
      "Requirement already satisfied: rsa==4.7.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (4.7.2)\n",
      "Requirement already satisfied: oauth2client>=2.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (4.1.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (0.4.8)\n",
      "Requirement already satisfied: pyu2f in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-reauth>=0.1.0->gsutil==5.5->-r ../requirements.txt (line 10)) (0.1.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httplib2>=0.18->gsutil==5.5->-r ../requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0->-r ../requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0->-r ../requirements.txt (line 9)) (4.4.0)\n",
      "Requirement already satisfied: cryptography<39,>=38.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyOpenSSL>=0.13->gsutil==5.5->-r ../requirements.txt (line 10)) (38.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (1.26.8)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (4.13.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: etils[epath] in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jax->trax==1.3.7->-r ../requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: opt-einsum in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jax->trax==1.3.7->-r ../requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: sacrebleu in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: editdistance in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.6.2)\n",
      "Requirement already satisfied: seqio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.0.14)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (1.12.1)\n",
      "Requirement already satisfied: babel in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (2.10.3)\n",
      "Requirement already satisfied: rouge-score in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.97)\n",
      "Requirement already satisfied: tfds-nightly in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (4.8.1.dev202301171228)\n",
      "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.21)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: promise in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (2.3)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (1.14.1)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (3.19.6)\n",
      "Requirement already satisfied: dm-tree in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.8)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.7.4)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cryptography<39,>=38.0.0->pyOpenSSL>=0.13->gsutil==5.5->-r ../requirements.txt (line 10)) (1.15.1)\n",
      "Requirement already satisfied: zipp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from etils[epath]->jax->trax==1.3.7->-r ../requirements.txt (line 7)) (3.10.0)\n",
      "Requirement already satisfied: importlib_resources in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from etils[epath]->jax->trax==1.3.7->-r ../requirements.txt (line 7)) (5.10.0)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from mesh-tensorflow[transformer]>=0.1.13->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.18.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (0.2.8)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.0.7)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.37.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (3.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (1.51.1)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.11.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (15.0.6.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.29.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (1.1.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: lxml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (4.9.2)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (2.6.0)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from sacrebleu->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.4.3)\n",
      "Requirement already satisfied: clu in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.0.8)\n",
      "Requirement already satisfied: pyglove in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (1.58.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cffi>=1.12->cryptography<39,>=38.0.0->pyOpenSSL>=0.13->gsutil==5.5->-r ../requirements.txt (line 10)) (2.21)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (0.6.1)\n",
      "Requirement already satisfied: flax in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: ml-collections in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (3.5.3)\n",
      "Requirement already satisfied: optax in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.4)\n",
      "Requirement already satisfied: tensorstore in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.30)\n",
      "Requirement already satisfied: rich~=11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (11.2.0)\n",
      "Requirement already satisfied: msgpack in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: contextlib2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ml-collections->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (21.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text->trax==1.3.7->-r ../requirements.txt (line 7)) (3.2.2)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rich~=11.1->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rich~=11.1->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (2.13.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (4.38.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from optax->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.1.5)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from chex>=0.1.5->optax->flax->clu->seqio->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# Upgrade dependencies\n",
    "! pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ea50c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torchtext in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchtext) (4.63.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchtext) (2.28.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchtext) (1.12.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchtext) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchtext) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch->torchtext) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "!pip install torchtext\n",
    "import re, time\n",
    "import numpy as np\n",
    "import torch, torchtext\n",
    "\n",
    "from os import path\n",
    "from collections import Counter\n",
    "from torch import nn, optim\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from torchtext.vocab import GloVe\n",
    "GloVe.url['6B'] = 'https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409aeb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ben Smith / Smith (concussion) remains out of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry bout the stream last night I crashed out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Headley's RBI double in the 8th inning o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  \"QT @user In the original draft of the 7th boo...      2\n",
       "1  \"Ben Smith / Smith (concussion) remains out of...      1\n",
       "2  Sorry bout the stream last night I crashed out...      1\n",
       "3  Chase Headley's RBI double in the 8th inning o...      1\n",
       "4  @user Alciato: Bee will invest 150 million in ...      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train_complete.csv', encoding='utf-8', header=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c729f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>hey PA can you um let me register for a medica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet\n",
       "count                                               12284\n",
       "unique                                              12284\n",
       "top     hey PA can you um let me register for a medica...\n",
       "freq                                                    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open('../data/test_text.txt') as f:\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "print(len(lines))\n",
    "test_df = pd.DataFrame (lines, columns = ['tweet'])\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff0a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21542\n",
      "2    18668\n",
      "0     7405\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_id_distribution = train_df['label'].value_counts()\n",
    "print(class_id_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bfad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing missing values...\n",
      "Splitting data into training and validation...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fixing missing values...\")\n",
    "train_df[\"tweet\"].fillna(\"\", inplace=True)\n",
    "\n",
    "print(\"Splitting data into training and validation...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df[\"tweet\"].tolist(),\n",
    "    train_df[\"label\"].tolist(),\n",
    "    test_size=0.10,\n",
    "    shuffle=True,\n",
    "    random_state=324,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3729537",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5200/3736702619.py\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(X_train_sample_class_2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_sample_class_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_sample_class_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_sample_class_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_sample_class_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_sample_class_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_sample_class_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 )\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'str'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# Making the samples equal for each class\n",
    "X_train_sample_class_0 = X_train[y_train == 0]\n",
    "X_train_sample_class_1 = X_train[y_train == 1]\n",
    "X_train_sample_class_2 = X_train[y_train == 2]\n",
    "\n",
    "from sklearn.utils import resample\n",
    "X_train_sample_class_1 = resample(X_train_sample_class_1,\n",
    "             replace=True,\n",
    "             n_samples=len(X_train_sample_class_0)+3000,\n",
    "             random_state=42)\n",
    "X_train_sample_class_2 = resample(X_train_sample_class_2,\n",
    "             replace=True,\n",
    "             n_samples=len(X_train_sample_class_0)+3000,\n",
    "             random_state=42)\n",
    "y_train_sample_class_0 = np.zeros(len(X_train_sample_class_0))\n",
    "y_train_sample_class_1 = np.ones(len(X_train_sample_class_1))\n",
    "y_train_sample_class_2 = np.repeat(2, len(X_train_sample_class_2))\n",
    "# print(X_train_sample_class_1.shape)\n",
    "# print(X_train_sample_class_2.shape)\n",
    "\n",
    "X_train = pd.concat([pd.concat([X_train_sample_class_0, X_train_sample_class_1]), X_train_sample_class_2])\n",
    "y_train = np.concatenate((np.concatenate((y_train_sample_class_0, y_train_sample_class_1), axis=0), y_train_sample_class_2), axis=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9133f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(X_train)):\n",
    "    sent = X_train[index]\n",
    "    if index==0:\n",
    "        print(X_train[index])\n",
    "    # Lowercase\n",
    "    sent = sent.lower()\n",
    "    # Remove leading/trailing whitespace\n",
    "    sent = sent.strip()\n",
    "    # Remove extra space and tabs\n",
    "    sent = re.sub(\"\\s+\", \" \", sent)\n",
    "    # Remove HTML tags/markups:\n",
    "    sent = re.compile(\"<.*?>\").sub(\"\", sent)\n",
    "    # initializing punctuations string\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "    # Removing punctuations in string\n",
    "    # Using loop + punctuation string\n",
    "    for ele in sent:\n",
    "        if ele in punc:\n",
    "            sent = sent.replace(ele, \"\")\n",
    "            \n",
    "    sent = ''.join([i for i in sent if not i.isdigit()])\n",
    "    \n",
    "    X_train[index] = sent\n",
    "    if index==0:\n",
    "        print(X_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5327d2e",
   "metadata": {},
   "source": [
    "### Text transformation\n",
    "We will apply the following processes here:\n",
    "1. Creating a vocabulary\n",
    "2. Text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "978a9452",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'min_freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26386/4171862405.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#min_freq>1 for skipping misspelled words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'min_freq'"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "counter = Counter()\n",
    "for line in X_train:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=2) #min_freq>1 for skipping misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e229493a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26386/2032511668.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Some examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'home' -> {vocab['home']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'wash' -> {vocab['wash']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# unknown word (assume from test set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'fhshbasdhb' -> {vocab['fhshbasdhb']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
     ]
    }
   ],
   "source": [
    "# Some examples\n",
    "print(f\"'home' -> {vocab['home']}\")\n",
    "print(f\"'wash' -> {vocab['wash']}\")\n",
    "# unknown word (assume from test set)\n",
    "print(f\"'fhshbasdhb' -> {vocab['fhshbasdhb']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcdebf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a mapper to transform our text data\n",
    "text_transform_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ae03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before transform:\\t{X_train[7]}\")\n",
    "print(f\"After transform:\\t{text_transform_pipeline(X_train[7])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_split, seq_length):\n",
    "    print(reviews_split)\n",
    "    # Transform the text\n",
    "    # use the dict to tokenize each review in reviews_split\n",
    "    # store the tokenized reviews in reviews_ints\n",
    "    reviews_ints = []\n",
    "    for review in reviews_split:\n",
    "        reviews_ints.append(text_transform_pipeline(review))\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.ones((len(reviews_ints), seq_length), dtype=int)\n",
    "    \n",
    "    # for each review, I grab that review\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return torch.tensor(features, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in X_train[9:11]:\n",
    "    print(f\"Text: {text}\\n\")\n",
    "    print(f\"Original length of the text: {len(text)}\\n\")\n",
    "    tt = pad_features([text], seq_length=100)\n",
    "    print(f\"Transformed text: \\n{tt}\\n\")\n",
    "    print(f\"Shape of transformed text: {tt.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6771392",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "batch_size = 64\n",
    "\n",
    "# Pass transformed and padded data to dataset\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(\n",
    "    pad_features(X_train, max_len), torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "val_dataset = TensorDataset(pad_features(X_val, max_len), torch.tensor(y_val, dtype=torch.float32))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73f77b",
   "metadata": {},
   "source": [
    "### Using pre-trained GloVe word embeddings\n",
    "\n",
    "In this example, we will use GloVe word vectors. `name='6B'` `dim=200` gives us 6 billion words/phrases vectors. Each word vector has 200 numbers in it. The following code shows how to get the word vectors and create an embedding matrix from them. We will connect our vocabulary indexes to the GloVe embedding with the `get_vecs_by_tokens()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = GloVe(name=\"6B\", dim=200)\n",
    "embedding_matrix = glove.get_vecs_by_tokens(vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the state vectors\n",
    "hidden_size = 128\n",
    "\n",
    "# General NN training parameters\n",
    "learning_rate = 0.0001\n",
    "epochs = 25\n",
    "\n",
    "# Embedding vector and vocabulary sizes\n",
    "embed_size = 200  # glove.6B.300d.txt\n",
    "vocab_size = len(vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d0e2f",
   "metadata": {},
   "source": [
    "Our model is made of these layers:\n",
    "\n",
    "- Embedding layer: This is where our words/tokens are mapped to word vectors.\n",
    "- RNN layer: We are using a simple RNN model. We stack 2 RNN layers in this example.\n",
    "- Linear layer: A linear layer with a single neuron is used to output the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be2d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=1)\n",
    "        self.rnn = nn.RNN(\n",
    "            embed_size, hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # Call the RNN layer\n",
    "        outputs, _ = self.rnn(embeddings)\n",
    "        \n",
    "        # Output shape after RNN: (batch_size, max_len, hidden_size)\n",
    "        # Get the output from the last time step with outputs[:, -1, :] below\n",
    "        # The output shape becomes: (batch_size, 1, hidden_size)\n",
    "        # Send it to the linear layer\n",
    "        outs = self.linear(outputs[:, -1, :])\n",
    "        return self.act(outs)\n",
    "    \n",
    "# Initialize the weights\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.RNN:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ebb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our architecture with 2 RNN layers\n",
    "model = Net(vocab_size, embed_size, hidden_size, num_layers=2)\n",
    "\n",
    "# We set the embedding layer's parameters from GloVe\n",
    "model.embedding.weight.data.copy_(embedding_matrix)\n",
    "# We won't change/train the embedding layer\n",
    "model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our trainer\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# We will use Binary Cross-entropy loss\n",
    "# reduction=\"sum\" sums the losses for given output and target\n",
    "cross_ent_loss = nn.BCELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the compute device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    val_loss = 0\n",
    "    # Training loop, train the network\n",
    "    for data, target in train_loader:\n",
    "        trainer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        L = cross_ent_loss(output, target.unsqueeze(1))\n",
    "        training_loss += L.item()\n",
    "        L.backward()\n",
    "        trainer.step()\n",
    "\n",
    "    # Validate the network, no training (no weight update)\n",
    "    for data, target in val_loader:\n",
    "        val_predictions = model(data.to(device))\n",
    "        L = cross_ent_loss(val_predictions, target.to(device).unsqueeze(1))\n",
    "        val_loss += L.item()\n",
    "\n",
    "    # Let's take the average losses\n",
    "    training_loss = training_loss / len(y_train)\n",
    "    val_loss = val_loss / len(y_val)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\n",
    "        f\"Epoch {epoch}. Train_loss {training_loss:.4f}. Val_loss {val_loss:.4f}. Seconds {end-start:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05872b9",
   "metadata": {},
   "source": [
    "## 3. Make predictions on your test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "380c6194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Implement this\n",
    "val_predictions = []\n",
    "for data, target in val_loader:\n",
    "    val_preds = model(data.to(device))\n",
    "    val_predictions.extend(\n",
    "        [np.rint(val_pred)[0] for val_pred in val_preds.detach().cpu().numpy()]\n",
    "    )\n",
    "print(val_predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cd428c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  730    0]\n",
      " [   0 2211    0]\n",
      " [   0 1821    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       730\n",
      "           1       0.46      1.00      0.63      2211\n",
      "           2       0.00      0.00      0.00      1821\n",
      "\n",
      "    accuracy                           0.46      4762\n",
      "   macro avg       0.15      0.33      0.21      4762\n",
      "weighted avg       0.22      0.46      0.29      4762\n",
      "\n",
      "Accuracy (validation): 0.46430071398572026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Use the fitted pipeline to make predictions on the validation dataset\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"Accuracy (validation):\", accuracy_score(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e837d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
