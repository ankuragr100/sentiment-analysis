{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting nvidia-ml-py3==7.352.0\n",
      "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pydantic==1.7.4\n",
      "  Downloading pydantic-1.7.4-cp39-cp39-manylinux2014_x86_64.whl (10.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk==3.6.2\n",
      "  Using cached nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "Collecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp39-cp39-manylinux1_x86_64.whl (9.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==0.24.1\n",
      "  Downloading scikit_learn-0.24.1-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trax==1.3.7\n",
      "  Using cached trax-1.3.7-py2.py3-none-any.whl (521 kB)\n",
      "Collecting transformers==4.5.1\n",
      "  Using cached transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting datasets==2.1.0\n",
      "  Using cached datasets-2.1.0-py3-none-any.whl (325 kB)\n",
      "Collecting gsutil==5.5\n",
      "  Using cached gsutil-5.5.tar.gz (2.9 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (4.63.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (2022.9.13)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from nltk==3.6.2->-r ../requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas==1.1.5->-r ../requirements.txt (line 4)) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas==1.1.5->-r ../requirements.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ../requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn==0.24.1->-r ../requirements.txt (line 5)) (1.8.1)\n",
      "Collecting jaxlib\n",
      "  Downloading jaxlib-0.4.1-cp39-cp39-manylinux2014_x86_64.whl (71.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting funcsigs\n",
      "  Using cached funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n",
      "Collecting t5\n",
      "  Using cached t5-0.9.3-py3-none-any.whl (153 kB)\n",
      "Collecting jax\n",
      "  Using cached jax-0.4.1.tar.gz (1.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (1.16.0)\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (5.9.3)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gym in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from trax==1.3.7->-r ../requirements.txt (line 7)) (0.26.2)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (3.6.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers==4.5.1->-r ../requirements.txt (line 8)) (21.3)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.3.6)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (2022.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets==2.1.0->-r ../requirements.txt (line 9)) (10.0.0)\n",
      "Collecting argcomplete>=1.9.4\n",
      "  Using cached argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting crcmod>=1.7\n",
      "  Using cached crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fasteners>=0.14.1\n",
      "  Using cached fasteners-0.18-py3-none-any.whl (18 kB)\n",
      "Collecting gcs-oauth2-boto-plugin>=3.0\n",
      "  Using cached gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-apitools>=0.5.32\n",
      "  Using cached google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
      "Collecting httplib2>=0.18\n",
      "  Using cached httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
      "Collecting google-reauth>=0.1.0\n",
      "  Using cached google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting monotonic>=1.4\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gsutil==5.5->-r ../requirements.txt (line 10)) (22.1.0)\n",
      "Collecting retry_decorator>=1.0.0\n",
      "  Using cached retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets==2.1.0->-r ../requirements.txt (line 9)) (4.0.2)\n",
      "Requirement already satisfied: rsa==4.7.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (4.7.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto>=2.29.1\n",
      "  Using cached boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting oauth2client>=2.2.0\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil==5.5->-r ../requirements.txt (line 10)) (0.4.8)\n",
      "Collecting pyu2f\n",
      "  Using cached pyu2f-0.1.5.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httplib2>=0.18->gsutil==5.5->-r ../requirements.txt (line 10)) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0->-r ../requirements.txt (line 9)) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.1.0->-r ../requirements.txt (line 9)) (5.4.1)\n",
      "Requirement already satisfied: cryptography<39,>=38.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pyOpenSSL>=0.13->gsutil==5.5->-r ../requirements.txt (line 10)) (38.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers==4.5.1->-r ../requirements.txt (line 8)) (1.26.8)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gym->trax==1.3.7->-r ../requirements.txt (line 7)) (4.13.0)\n",
      "Collecting jax\n",
      "  Using cached jax-0.3.25.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.24.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.23.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.22.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.21.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.20.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.19.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.17.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.16.tar.gz (1.0 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached jax-0.3.15.tar.gz (1.0 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting opt_einsum\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting etils[epath]\n",
      "  Using cached etils-1.0.0-py3-none-any.whl (146 kB)\n",
      "Collecting jaxlib\n",
      "  Downloading jaxlib-0.3.25-cp39-cp39-manylinux2014_x86_64.whl (71.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading jaxlib-0.3.24-cp39-cp39-manylinux2014_x86_64.whl (70.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading jaxlib-0.3.22-cp39-cp39-manylinux2014_x86_64.whl (72.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading jaxlib-0.3.20-cp39-cp39-manylinux2014_x86_64.whl (72.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading jaxlib-0.3.15-cp39-none-manylinux2014_x86_64.whl (72.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: babel in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (2.10.3)\n",
      "Collecting editdistance\n",
      "  Downloading editdistance-0.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.4/282.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Collecting seqio\n",
      "  Using cached seqio-0.0.14-py3-none-any.whl (320 kB)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from t5->trax==1.3.7->-r ../requirements.txt (line 7)) (1.12.1)\n",
      "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
      "  Using cached mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
      "Collecting tfds-nightly\n",
      "  Using cached tfds_nightly-4.8.2.dev202301190044-py3-none-any.whl (5.3 MB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (3.20.2)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: toml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (0.10.2)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tensorflow-datasets->trax==1.3.7->-r ../requirements.txt (line 7)) (1.14.1)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-hub>=0.8.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow<2.12,>=2.11.0\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from cryptography<39,>=38.0.0->pyOpenSSL>=0.13->gsutil==5.5->-r ../requirements.txt (line 10)) (1.15.1)\n",
      "Requirement already satisfied: importlib_resources in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from etils[epath]->jax->trax==1.3.7->-r ../requirements.txt (line 7)) (5.10.0)\n",
      "Requirement already satisfied: zipp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from etils[epath]->jax->trax==1.3.7->-r ../requirements.txt (line 7)) (3.10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from mesh-tensorflow[transformer]>=0.1.13->t5->trax==1.3.7->-r ../requirements.txt (line 7)) (0.18.2)\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting protobuf>=3.12.2\n",
      "  Using cached protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
      "INFO: pip is looking at multiple versions of oauth2client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting oauth2client>=2.2.0\n",
      "  Using cached oauth2client-4.1.2-py2.py3-none-any.whl (99 kB)\n",
      "INFO: pip is looking at multiple versions of multidict to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of mesh-tensorflow[transformer] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
      "  Using cached mesh_tensorflow-0.1.20-py3-none-any.whl (385 kB)\n",
      "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Using cached importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "INFO: pip is looking at multiple versions of gym-notices to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of frozenlist to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of etils[enp,epath] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting etils[enp,epath]>=0.9.0\n",
      "  Using cached etils-0.9.0-py3-none-any.whl (140 kB)\n",
      "INFO: pip is looking at multiple versions of cryptography to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cryptography<39,>=38.0.0\n",
      "  Using cached cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
      "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "INFO: pip is looking at multiple versions of etils[enp,epath] to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "INFO: pip is looking at multiple versions of boto to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting boto>=2.29.1\n",
      "  Using cached boto-2.48.0-py2.py3-none-any.whl (1.4 MB)\n",
      "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of async-timeout to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "INFO: pip is looking at multiple versions of aiosignal to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "INFO: pip is looking at multiple versions of xxhash to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.0/212.0 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.11,>=2.10.0\n",
      "  Downloading tensorflow-2.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.11,>=2.10.0\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.10,>=2.9.0\n",
      "  Downloading tensorflow-2.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.8.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.9,>=2.8.0\n",
      "  Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl (498.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.9,>=2.8.0\n",
      "  Downloading tensorflow-2.8.3-cp39-cp39-manylinux2010_x86_64.whl (498.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.5/498.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.8.2-cp39-cp39-manylinux2010_x86_64.whl (498.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.8.1-cp39-cp39-manylinux2010_x86_64.whl (498.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.8.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading tensorflow_text-2.7.3-cp39-cp39-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow<2.8,>=2.7.0\n",
      "  Downloading tensorflow-2.7.4-cp39-cp39-manylinux2010_x86_64.whl (496.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m380.7/496.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:01:17\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 437, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 560, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 526, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 94, in read\n",
      "    self.__buf.write(data)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/tempfile.py\", line 478, in func_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 160, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/cli/req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/commands/install.py\", line 400, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 373, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 204, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/resolvelib/structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 491, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 536, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/operations/prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/network/download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/cli/progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_internal/network/utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 621, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 586, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/pip/_vendor/urllib3/response.py\", line 454, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "pip._vendor.urllib3.exceptions.ProtocolError: (\"Connection broken: OSError(28, 'No space left on device')\", OSError(28, 'No space left on device'))\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Upgrade dependencies\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets==2.1.0\n",
    "import boto3\n",
    "import os\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the dataset\n",
    "\n",
    "We will use the __pandas__ library to read our dataset. Let's first download the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Training data:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"QT @user In the original draft of the 7th boo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Ben Smith / Smith (concussion) remains out of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorry bout the stream last night I crashed out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chase Headley's RBI double in the 8th inning o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Alciato: Bee will invest 150 million in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  \"QT @user In the original draft of the 7th boo...      2\n",
       "1  \"Ben Smith / Smith (concussion) remains out of...      1\n",
       "2  Sorry bout the stream last night I crashed out...      1\n",
       "3  Chase Headley's RBI double in the 8th inning o...      1\n",
       "4  @user Alciato: Bee will invest 150 million in ...      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/train_complete.csv', encoding='utf-8', header=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Test data:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  @user @user what do these '1/2 naked pics' hav...\n",
       "1  OH: “I had a blue penis while I was this” [pla...\n",
       "2  @user @user That's coming, but I think the vic...\n",
       "3  I think I may be finally in with the in crowd ...\n",
       "4  @user Wow,first Hugo Chavez and now Fidel Cast..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "with open('../data/test_text.txt') as f:\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "print(len(lines))\n",
    "test_df = pd.DataFrame (lines, columns = ['tweet'])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47615 entries, 0 to 47614\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   47615 non-null  object\n",
      " 1   label   47615 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 744.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21542\n",
      "2    18668\n",
      "0     7405\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is imbalance\n",
    "class_id_distribution = train_df['label'].value_counts()\n",
    "print(class_id_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(subset=[\"tweet\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\r\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.22.4)\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15816/1285637912.py\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistilBertTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This separates 10% of the entire train dataset into validation dataset.\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df[[\"tweet\"]],\n",
    "    train_df[\"label\"].values,\n",
    "#     train_df[\"tweet\"].tolist(),\n",
    "#     train_df[\"label\"].values.tolist(),\n",
    "    test_size=0.10,\n",
    "    shuffle=True,\n",
    "    random_state=324,\n",
    "    stratify = train_df[\"label\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9664, 1)\n",
      "(9664, 1)\n",
      "(25992, 1)\n",
      "(25992,)\n"
     ]
    }
   ],
   "source": [
    "# Making the samples equal for each class\n",
    "X_train_sample_class_0 = train_texts[train_labels == 0]\n",
    "X_train_sample_class_1 = train_texts[train_labels == 1]\n",
    "X_train_sample_class_2 = train_texts[train_labels == 2]\n",
    "\n",
    "from sklearn.utils import resample\n",
    "X_train_sample_class_1 = resample(X_train_sample_class_1,\n",
    "             replace=True,\n",
    "             n_samples=X_train_sample_class_0.shape[0]+3000,\n",
    "             random_state=42)\n",
    "X_train_sample_class_2 = resample(X_train_sample_class_2,\n",
    "             replace=True,\n",
    "             n_samples=X_train_sample_class_0.shape[0]+3000,\n",
    "             random_state=42)\n",
    "y_train_sample_class_0 = np.zeros(X_train_sample_class_0.shape[0])\n",
    "y_train_sample_class_1 = np.ones(X_train_sample_class_1.shape[0])\n",
    "y_train_sample_class_2 = np.repeat(2, X_train_sample_class_2.shape[0])\n",
    "print(X_train_sample_class_1.shape)\n",
    "print(X_train_sample_class_2.shape)\n",
    "\n",
    "train_texts = pd.concat([pd.concat([X_train_sample_class_0, X_train_sample_class_1]), X_train_sample_class_2])\n",
    "train_labels = np.concatenate((np.concatenate((y_train_sample_class_0, y_train_sample_class_1), axis=0), y_train_sample_class_2), axis=0)\n",
    "print(train_texts.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def process_text(texts):\n",
    "#     final_text_list = []\n",
    "#     for sent in texts:\n",
    "\n",
    "#         # Check if the sentence is a missing value\n",
    "#         if isinstance(sent, str) == False:\n",
    "#             sent = \"\"\n",
    "\n",
    "#         filtered_sentence = []\n",
    "        \n",
    "#         # Lowercase\n",
    "#         sent = sent.lower()\n",
    "#         # Remove leading/trailing whitespace\n",
    "#         sent = sent.strip()\n",
    "#         # Remove extra space and tabs\n",
    "#         sent = re.sub(\"\\s+\", \" \", sent)\n",
    "#         # Remove HTML tags/markups:\n",
    "#         sent = re.compile(\"<.*?>\").sub(\"\", sent)\n",
    "        \n",
    "#         punc = '''!\"'#$%&()*+,-./:;<=>?@[\\]^_`{|}~'''\n",
    "\n",
    "#         # Removing punctuations in string\n",
    "#         # Using loop + punctuation string\n",
    "#         for ele in sent:\n",
    "#             if ele in punc:\n",
    "#                 sent = sent.replace(ele, \"\")\n",
    "        \n",
    "# #         sent = ''.join([i for i in sent if not i.isdigit()])\n",
    "\n",
    "# #         words = word_tokenize(sent)\n",
    "    \n",
    "# #         #NOTHING\n",
    "# #         for w in words:\n",
    "# #             if (not w.isnumeric()) and len(w)>3:\n",
    "# #                 filtered_sentence.append(w)\n",
    "        \n",
    "# #         #STEMMING\n",
    "# #         for w in words:\n",
    "# #             # Check if it is not numeric and its length>2 and not in stop words\n",
    "# #             if (not w.isnumeric()) and (len(w) > 2):\n",
    "# #                 # Stem and add to filtered list\n",
    "# #                 filtered_sentence.append(snow.stem(w))\n",
    "\n",
    "# #         #LEMMITIZATION\n",
    "# #         wl = WordNetLemmatizer()\n",
    "# #         for w in words:\n",
    "# #             if (not w.isnumeric()) and (w not in stop_words):\n",
    "# #                 filtered_sentence.append(w)\n",
    "# #         sent = \" \".join(filtered_sentence)\n",
    "# #         filtered_sentence = []\n",
    "        \n",
    "# #         words = word_tokenize(sent)\n",
    "# #         # Get position tags\n",
    "# #         word_pos_tags = nltk.pos_tag(words)\n",
    "# #         # Map the position tag and lemmatize the word/token\n",
    "# #         for idx, tag in enumerate(word_pos_tags):\n",
    "# #             filtered_sentence.append(wl.lemmatize(tag[0], get_wordnet_pos(tag[1])))\n",
    "    \n",
    "# #         final_string = \" \".join(sent)  # final string of cleaned words\n",
    "\n",
    "#         final_text_list.append(sent)\n",
    "\n",
    "#     return final_text_list\n",
    "\n",
    "# print(\"Processing the text fields...\")\n",
    "# train_texts[\"tweet\"] = process_text(train_texts[\"tweet\"].tolist())\n",
    "# val_texts[\"tweet\"] = process_text(val_texts[\"tweet\"].tolist())\n",
    "# print(train_texts.shape)\n",
    "# print(val_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words removal and stemming\n",
    "# Let's get a list of stop words from the NLTK library\n",
    "stop = stopwords.words(\"english\")\n",
    "stop_words = [word for word in stop]\n",
    "\n",
    "snow = SnowballStemmer(\"english\")\n",
    "\n",
    "def process_text(texts):\n",
    "    final_text_list = []\n",
    "    for sent in texts:\n",
    "\n",
    "        filtered_sentence = []\n",
    "        \n",
    "        # convert to lowercase\n",
    "        sent = sent.lower()\n",
    "        # Remove leading/trailing whitespace\n",
    "        sent = sent.strip()\n",
    "        # Remove extra space and tabs\n",
    "        sent = re.sub(\"\\s+\", \" \", sent)\n",
    "        # Remove retweets, links, hashtags\n",
    "        sent = re.sub('@[^\\s]+','',sent) \n",
    "        sent = re.sub('http[^\\s]+','',sent)\n",
    "        sent = re.sub('#[^\\s]+','',sent)\n",
    "        # Remove numerics\n",
    "        sent = ''.join([i for i in sent if not i.isdigit()])\n",
    "        # Remove emojis\n",
    "        emojis = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U00002702-\\U000027B0\"\n",
    "            u\"\\U000024C2-\\U0001F251\"\n",
    "            u\"\\U0001f926-\\U0001f937\"\n",
    "            u\"\\U00010000-\\U0010ffff\"\n",
    "            u\"\\u2640-\\u2642\" \n",
    "            u\"\\u2600-\\u2B55\"\n",
    "            u\"\\u200d\"\n",
    "            u\"\\u23cf\"\n",
    "            u\"\\u23e9\"\n",
    "            u\"\\u231a\"\n",
    "            u\"\\ufe0f\"  # dingbats\n",
    "            u\"\\u3030\"\"]+\", re.UNICODE)\n",
    "        sent = re.sub(emojis, '', sent)\n",
    "        # Remove some unicode characters\n",
    "        sent = sent.replace('\\u2019', '')\n",
    "        sent = sent.replace('\\u002c', '')\n",
    "        \n",
    "        # Tokenize the sentence\n",
    "        words = word_tokenize(sent)\n",
    "        \n",
    "        for i in range(len(words)):\n",
    "            filtered_sentence.append((words[i]))\n",
    "            \n",
    "#         #STEMMING\n",
    "#         for i in range(len(words)):\n",
    "#             # Check if its length>2\n",
    "#             if len(words[i])>2:\n",
    "#                 # Stem and add to filtered list\n",
    "#                 filtered_sentence.append(snow.stem(words[i]))\n",
    "    \n",
    "        final_string = \" \".join(filtered_sentence)  # final string of cleaned words\n",
    "\n",
    "        final_text_list.append(final_string)\n",
    "\n",
    "    return final_text_list\n",
    "\n",
    "print(\"Processing the text fields...\")\n",
    "\n",
    "train_texts[\"tweet\"] = process_text(train_texts[\"tweet\"].tolist())\n",
    "val_texts[\"tweet\"] = process_text(val_texts[\"tweet\"].tolist())\n",
    "test_df[\"tweet\"] = process_text(test_df[\"tweet\"].tolist())\n",
    "print(train_texts.shape)\n",
    "print(val_texts.shape)\n",
    "\n",
    "# Remove punctuations\n",
    "punctuations_list = string.punctuation\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "train_texts[\"tweet\"] = train_texts[\"tweet\"].apply(lambda x: cleaning_punctuations(x))\n",
    "val_texts[\"tweet\"] = val_texts[\"tweet\"].apply(lambda x: cleaning_punctuations(x))\n",
    "test_df[\"tweet\"] = test_df[\"tweet\"].apply(lambda x: cleaning_punctuations(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_texts['tweet'].astype(str).tolist()\n",
    "val_texts = val_texts['tweet'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(train_texts,\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "val_encodings = tokenizer(val_texts,\n",
    "                          truncation=True,\n",
    "                          padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "class ReviewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = ReviewDataset(train_encodings, train_labels)\n",
    "val_dataset = ReviewDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",\n",
    "                                                            num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train_loss 0.8465. Val_loss 0.8220.     Val_accuracy 0.5805. Seconds 46.471.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Train_loss 0.8392. Val_loss 0.8412.     Val_accuracy 0.5744. Seconds 47.141.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Train_loss 0.8367. Val_loss 0.8227.     Val_accuracy 0.5884. Seconds 47.088.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Train_loss 0.8291. Val_loss 0.8340.     Val_accuracy 0.5865. Seconds 47.089.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Train_loss 0.8258. Val_loss 0.8242.     Val_accuracy 0.5951. Seconds 47.470.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Train_loss 0.8195. Val_loss 0.8109.     Val_accuracy 0.5964. Seconds 47.190.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Train_loss 0.8157. Val_loss 0.7982.     Val_accuracy 0.6015. Seconds 48.409.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Train_loss 0.8132. Val_loss 0.8375.     Val_accuracy 0.5770. Seconds 50.756.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8. Train_loss 0.8121. Val_loss 0.8163.     Val_accuracy 0.5907. Seconds 54.012.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Train_loss 0.8107. Val_loss 0.8063.     Val_accuracy 0.6004. Seconds 54.113.\n"
     ]
    }
   ],
   "source": [
    "# Implement this\n",
    "# Freeze the encoder weights until the classfier\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate=0.001\n",
    "\n",
    "# Get the compute device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, drop_last=True)\n",
    "eval_dataloader = DataLoader(val_dataset, batch_size=8, drop_last=True)\n",
    "\n",
    "# Setup the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "model=model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    training_loss = 0\n",
    "    val_loss = 0\n",
    "    # Training loop starts\n",
    "    model.train() # put the model in training mode\n",
    "    for batch in train_dataloader:\n",
    "        # below: ** allows us to pass multiple arguments to model()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        training_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    # Validation loop starts\n",
    "    model.eval() # put the model in prediction mode\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            # below:  ** allows us to pass multiple arguments to model()\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        val_loss += loss.item()\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        \n",
    "    # Let's take the average losses\n",
    "    training_loss = training_loss / len(train_dataloader)\n",
    "    val_loss = val_loss / len(eval_dataloader)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Epoch {epoch}. Train_loss {training_loss:.4f}. Val_loss {val_loss:.4f}. \\\n",
    "    Val_accuracy {metric.compute(average='macro')['f1']:.4f}. Seconds {end-start:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the val predictions\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4)\n",
    "val_predictions = []\n",
    "model.eval()\n",
    "for batch in val_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    val_predictions.extend(predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14622/3879171852.py:9: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Check the train predictions\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
    "train_predictions = []\n",
    "model.eval()\n",
    "for batch in train_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    train_predictions.extend(predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the val predictions\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
    "val_predictions = []\n",
    "model.eval()\n",
    "for batch in val_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    val_predictions.extend(predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 460  205   76]\n",
      " [ 367 1375  412]\n",
      " [ 158  613 1096]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.62      0.53       741\n",
      "           1       0.63      0.64      0.63      2154\n",
      "           2       0.69      0.59      0.64      1867\n",
      "\n",
      "    accuracy                           0.62      4762\n",
      "   macro avg       0.60      0.62      0.60      4762\n",
      "weighted avg       0.63      0.62      0.62      4762\n",
      "\n",
      "Accuracy (validation): 0.615497690046199\n"
     ]
    }
   ],
   "source": [
    "# Check the confusion matrix of validation dataset\n",
    "y_val = val_labels\n",
    "# y_val = y_val.detach().cpu().numpy()\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"Accuracy (validation):\", accuracy_score(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4359 1636  669]\n",
      " [1585 6194 1885]\n",
      " [ 817 2845 6002]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.65      0.65      6664\n",
      "         1.0       0.58      0.64      0.61      9664\n",
      "         2.0       0.70      0.62      0.66      9664\n",
      "\n",
      "    accuracy                           0.64     25992\n",
      "   macro avg       0.64      0.64      0.64     25992\n",
      "weighted avg       0.64      0.64      0.64     25992\n",
      "\n",
      "Accuracy (training): 0.6369267466912897\n"
     ]
    }
   ],
   "source": [
    "# Check the confusion matrix of train dataset\n",
    "y_train = train_labels\n",
    "# y_val = y_val.detach().cpu().numpy()\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Accuracy (training):\", accuracy_score(y_train, train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on your test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12032, 1)\n"
     ]
    }
   ],
   "source": [
    "# Implement this\n",
    "print(test_df.shape)\n",
    "test_df.isna().sum()\n",
    "test_df[\"tweet\"] = test_df[\"tweet\"].fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df[\"tweet\"].tolist()\n",
    "test_encodings = tokenizer(test_texts,\n",
    "                          truncation=True,\n",
    "                          padding=True)\n",
    "test_dataset = ReviewDataset(test_encodings, [0]*len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=4)\n",
    "test_predictions = []\n",
    "model.eval()\n",
    "for batch in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    test_predictions.extend(predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12032\n"
     ]
    }
   ],
   "source": [
    "print(len(test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write your predictions to a CSV file\n",
    "You can use the following code to write your test predictions to a CSV file. Then upload your file to https://mlu.corp.amazon.com/contests/redirect/53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df[\"tweet\"] = test_df[\"tweet\"]\n",
    "result_df[\"label\"] = test_predictions\n",
    " \n",
    "result_df.to_csv(\"../../data/open_data_sentiment_analysis/result.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
